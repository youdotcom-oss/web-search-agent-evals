{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Search Agent Evaluations - Results Analysis\n",
    "\n",
    "Analysis of evaluation results comparing 4 CLI agents (Claude Code, Gemini, Droid, Codex) with 2 search tools (builtin, You.com MCP).\n",
    "\n",
    "## Quick Navigation\n",
    "\n",
    "1. [Setup & Data Loading](#setup)\n",
    "2. [Executive Summary](#summary)\n",
    "3. [Rankings](#rankings)\n",
    "4. [Score Distribution](#distribution)\n",
    "5. [Pass Rates](#pass-rates)\n",
    "6. [Latency Analysis](#latency)\n",
    "7. [Tool Errors](#errors)\n",
    "8. [Dataset Summary](#dataset)\n",
    "\n",
    "## Methodology\n",
    "\n",
    "- **Prompts**: 151 web search tasks\n",
    "- **Configurations**: 8 (4 agents √ó 2 search tools)\n",
    "- **Scoring**: Deterministic (60%) + LLM judge (35%) + Metadata (5%)\n",
    "- **Pass Threshold**: 70% score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Colab Setup (auto-detects environment)\nimport os\nfrom pathlib import Path\n\n# Detect if running in Colab\ntry:\n    import google.colab\n    IN_COLAB = True\nexcept ImportError:\n    IN_COLAB = False\n\nif IN_COLAB:\n    print(\"üîß Running in Google Colab - cloning repository...\")\n    \n    # Clone repository if not already present\n    repo_dir = Path('/content/web-search-agent-evals')\n    if not repo_dir.exists():\n        !git clone https://github.com/youdotcom-oss/web-search-agent-evals.git /content/web-search-agent-evals\n        print(\"‚úì Repository cloned\")\n    else:\n        print(\"‚úì Repository already exists\")\n        # Pull latest changes\n        %cd /content/web-search-agent-evals\n        !git pull origin main\n    \n    # Change to repo directory\n    %cd /content/web-search-agent-evals\n    print(f\"‚úì Working directory: {Path.cwd()}\")\nelse:\n    print(\"‚úì Running locally\")"
  },
  {
   "cell_type": "code",
   "source": "# Cell 2: Dependencies & Configuration\nimport json\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\n\n# Configure plotting\nsns.set_style('whitegrid')\nplt.rcParams['figure.dpi'] = 100\n\n# Find project root\nPROJECT_ROOT = Path.cwd()\nif PROJECT_ROOT.name == 'notebooks':\n    PROJECT_ROOT = PROJECT_ROOT.parent\n\nDATA_DIR = PROJECT_ROOT / 'data'\nprint(f\"üìÅ Project root: {PROJECT_ROOT}\")\nprint(f\"üìä Data directory: {DATA_DIR}\")\n\n# Verify data directory exists\nif not DATA_DIR.exists():\n    raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}. Make sure you're in the project root.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load Latest Run Metadata\n",
    "# Read latest run pointer\n",
    "with open(DATA_DIR / 'results' / 'latest.json') as f:\n",
    "    latest = json.load(f)\n",
    "\n",
    "print(f\"üìä Latest Run: {latest['date']}\")\n",
    "print(f\"   Prompts: {latest['promptCount']}\")\n",
    "print(f\"   Path: {latest['path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Load Raw Trajectory Data\n",
    "# Read MANIFEST for agent/provider list\n",
    "with open(DATA_DIR / 'results' / 'MANIFEST.jsonl') as f:\n",
    "    manifest_entry = json.loads(f.readlines()[-1])\n",
    "    agents = manifest_entry['agents']\n",
    "    providers = manifest_entry['searchProviders']\n",
    "\n",
    "# Load all trajectory results\n",
    "rows = []\n",
    "for agent in agents:\n",
    "    for provider in providers:\n",
    "        result_file = DATA_DIR / 'results' / latest['path'] / agent / f\"{provider}.jsonl\"\n",
    "        \n",
    "        if not result_file.exists():\n",
    "            print(f\"‚ö†Ô∏è  Missing: {result_file}\")\n",
    "            continue\n",
    "        \n",
    "        with open(result_file) as f:\n",
    "            for line in f:\n",
    "                record = json.loads(line)\n",
    "                \n",
    "                # Extract nested score (critical fix!)\n",
    "                score_obj = record.get('score', {})\n",
    "                numeric_score = score_obj.get('score', 0) if isinstance(score_obj, dict) else 0\n",
    "                pass_flag = score_obj.get('pass', False) if isinstance(score_obj, dict) else False\n",
    "                \n",
    "                rows.append({\n",
    "                    'agent': agent,\n",
    "                    'provider': provider,\n",
    "                    'config': f\"{agent}-{provider}\",\n",
    "                    'id': record['id'],\n",
    "                    'score': numeric_score,\n",
    "                    'pass': pass_flag,\n",
    "                    'latency_ms': record.get('timing', {}).get('total', 0),\n",
    "                    'tool_errors': record.get('toolErrors', False),\n",
    "                })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(f\"‚úì Loaded {len(df):,} trajectory records\")\n",
    "print(f\"  Agents: {', '.join(agents)}\")\n",
    "print(f\"  Providers: {', '.join(providers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Load Comparison Data\n",
    "comp_file = DATA_DIR / 'comparisons' / latest['path'] / 'all-weighted.json'\n",
    "\n",
    "if comp_file.exists():\n",
    "    with open(comp_file) as f:\n",
    "        comparison = json.load(f)\n",
    "    \n",
    "    # Extract rankings\n",
    "    rankings = []\n",
    "    for config, metrics in comparison['quality'].items():\n",
    "        rankings.append({\n",
    "            'config': config,\n",
    "            'avgScore': metrics['avgScore'],\n",
    "            'passRate': metrics['passRate'],\n",
    "            'passCount': metrics['passCount'],\n",
    "            'failCount': metrics['failCount']\n",
    "        })\n",
    "    \n",
    "    rankings_df = pd.DataFrame(rankings).sort_values('avgScore', ascending=False)\n",
    "    rankings_df['rank'] = range(1, len(rankings_df) + 1)\n",
    "    \n",
    "    print(f\"‚úì Loaded comparison data: {len(rankings_df)} configurations\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  No comparison file found: {comp_file}\")\n",
    "    comparison = None\n",
    "    rankings_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "## Executive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Executive Summary\n",
    "if rankings_df is not None:\n",
    "    print(f\"üìä WEB SEARCH AGENT EVALUATIONS\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Run Date: {latest['date']}\")\n",
    "    print(f\"Prompts: {latest['promptCount']}\")\n",
    "    print(f\"Configurations: {len(rankings_df)} (4 agents √ó 2 search tools)\")\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"TOP 3 CONFIGURATIONS\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    for _, row in rankings_df.head(3).iterrows():\n",
    "        print(f\"#{int(row['rank'])} {row['config']}\")\n",
    "        print(f\"   Score: {row['avgScore']:.1%} | Pass Rate: {row['passRate']:.1%}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rankings'></a>\n",
    "## Configuration Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Rankings Bar Chart\n",
    "if rankings_df is not None:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    colors = ['#2ecc71' if i < 3 else '#3498db' for i in range(len(rankings_df))]\n",
    "    bars = ax.barh(rankings_df['config'], rankings_df['avgScore'] * 100, color=colors)\n",
    "    \n",
    "    ax.set_xlabel('Average Score (%)')\n",
    "    ax.set_ylabel('Configuration')\n",
    "    ax.set_title('Agent Rankings by Quality Score')\n",
    "    ax.axvline(x=70, color='red', linestyle='--', alpha=0.5, label='Pass Threshold')\n",
    "    ax.legend()\n",
    "    \n",
    "    for bar, score in zip(bars, rankings_df['avgScore']):\n",
    "        ax.text(score * 100 + 0.5, bar.get_y() + bar.get_height()/2,\n",
    "                f\"{score*100:.1f}%\", va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='distribution'></a>\n",
    "## Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Score Distribution (Violin Plot)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "sns.violinplot(data=df, y='config', x='score', ax=ax, inner='quartile')\n",
    "ax.axvline(x=0.7, color='red', linestyle='--', alpha=0.5, label='Pass Threshold')\n",
    "ax.set_xlabel('Score')\n",
    "ax.set_ylabel('Configuration')\n",
    "ax.set_title('Score Distribution by Configuration')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nüìä SCORE STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "for config in sorted(df['config'].unique()):\n",
    "    scores = df[df['config'] == config]['score']\n",
    "    print(f\"\\n{config}:\")\n",
    "    print(f\"  Mean: {scores.mean():.3f} | Median: {scores.median():.3f} | Std: {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pass-rates'></a>\n",
    "## Pass Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Pass Rates\n",
    "pass_rates = df.groupby('config')['pass'].mean().sort_values(ascending=False) * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = ['#2ecc71' if rate >= 20 else '#f39c12' if rate >= 10 else '#e74c3c'\n",
    "          for rate in pass_rates]\n",
    "bars = ax.barh(pass_rates.index, pass_rates.values, color=colors)\n",
    "\n",
    "ax.set_xlabel('Pass Rate (%)')\n",
    "ax.set_ylabel('Configuration')\n",
    "ax.set_title('Pass Rates (Score ‚â• 70%)')\n",
    "\n",
    "for bar, rate in zip(bars, pass_rates.values):\n",
    "    ax.text(rate + 0.5, bar.get_y() + bar.get_height()/2,\n",
    "            f\"{rate:.1f}%\", va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='latency'></a>\n",
    "## Latency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Latency Analysis\n",
    "latency_stats = df.groupby('config')['latency_ms'].agg([\n",
    "    'median',\n",
    "    ('p90', lambda x: x.quantile(0.9))\n",
    "]).sort_values('median')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = range(len(latency_stats))\n",
    "ax.barh(x, latency_stats['median'], label='Median', alpha=0.7, color='#3498db')\n",
    "ax.barh(x, latency_stats['p90'], label='P90', alpha=0.5, color='#e74c3c')\n",
    "\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(latency_stats.index)\n",
    "ax.set_xlabel('Latency (ms)')\n",
    "ax.set_ylabel('Configuration')\n",
    "ax.set_title('Response Time Distribution')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nLatency Summary (ms):\")\n",
    "print(latency_stats.round(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='errors'></a>\n",
    "## Tool Error Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Tool Error Rates\n",
    "error_rates = df.groupby('config')['tool_errors'].mean().sort_values(ascending=False) * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = ['#e74c3c' if rate > 20 else '#f39c12' if rate > 10 else '#2ecc71'\n",
    "          for rate in error_rates]\n",
    "bars = ax.barh(error_rates.index, error_rates.values, color=colors)\n",
    "\n",
    "ax.set_xlabel('Error Rate (%)')\n",
    "ax.set_ylabel('Configuration')\n",
    "ax.set_title('Tool Error Rates')\n",
    "\n",
    "for bar, rate in zip(bars, error_rates.values):\n",
    "    ax.text(rate + 0.5, bar.get_y() + bar.get_height()/2,\n",
    "            f\"{rate:.1f}%\", va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataset'></a>\n",
    "## Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Data Summary\n",
    "print(\"üìã DATASET SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total Records: {len(df):,}\")\n",
    "print(f\"Agents: {df['agent'].nunique()}\")\n",
    "print(f\"Providers: {df['provider'].nunique()}\")\n",
    "print(f\"Configurations: {df['config'].nunique()}\")\n",
    "print(f\"Unique Prompts: {df['id'].nunique()}\")\n",
    "print(f\"\\nScore Range: {df['score'].min():.3f} - {df['score'].max():.3f}\")\n",
    "print(f\"Pass Rate (overall): {df['pass'].mean():.1%}\")\n",
    "print(f\"Avg Latency: {df['latency_ms'].mean():.0f}ms\")\n",
    "print(f\"Tool Error Rate: {df['tool_errors'].mean():.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}